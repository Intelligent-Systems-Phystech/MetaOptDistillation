\documentclass[12pt, twoside]{article}
\usepackage{jmlda}
\newcommand{\hdir}{.}

\begin{document}

\title
    [Оптимизация параметров модели на основе дистилляции знаний] % краткое название; не нужно, если полное название влезает в~колонтитул
    {Регуляризация траектории оптимизации параметров модели глубокого обучения на основе дистилляции знаний}
\author
    [М.~Горпинич] % список авторов (не более трех) для колонтитула; не нужен, если основной список влезает в колонтитул
    {М.~Горпинич, О.\,Ю.~Бахтеев, В.\,В.~Стрижов} % основной список авторов, выводимый в оглавление
    [М.~Горпинич, О.\,Ю.~Бахтеев, В.\,В.~Стрижов] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\email
    {gorpinich4@gmail.com; bakhteev@phystech.edu;  strijov@ccas.ru}
%\thanks
%    {Работа выполнена при
%     частичной
%     финансовой поддержке РФФИ, проекты \No\ \No 00-00-00000 и 00-00-00001.}
%\organization
%    {$^1$Организация, адрес; $^2$Организация, адрес}
\abstract
    {Исследуется задача оптимизации параметров модели глубокого обучения. Предлагается обобщение методов дистилляции, заключающееся в градиентной оптимизации гиперпараметров. На первом уровне оптимизируются параметры модели, на втором --- гиперпараметры, задающие вид оптимизационной задачи. Исследуются свойства оптимизационной задачи и различные виды оператора оптимизации. Предложенное обобщение оптимизации позволяет производить дистилляцию модели с лучшими эксплуатационными характеристиками и за меньшее количество итераций оптимизации. Иллюстрировать применение комбинации данных подходов предлагается с помощью вычислительного эксперимента на выборке CIFAR-10.
	
\bigskip
\noindent
\textbf{Ключевые слова}: \emph {}
}

%данные поля заполняются редакцией журнала
\doi{}
\receivedRus{}
\receivedEng{}

\maketitle
\linenumbers

\section{Введение}
В работе рассматривается задача оптимизации моделей глубоких нейросетей. Данная задача требует значительных вычислительных мощностей и является затратной по времени. В данной работе предлагается метод оптимизации, позволяющий улучшить эксплуатационные характеристики модели, а также ускорить ее сходимость к точке оптимума.

Предлагается обобщение метода оптимизации на основе дистилляции знаний. Рассматривается \textit{модель-учитель} более сложной структуры, которая была обучена на выборке. Модель более простой структуры предлагается оптимизировать путем переноса знаний модели учителя на более простую модель, называемую \textit{моделью-учеником}, при этом ее качество будет выше по сравнению с качеством, полученным после оптимизации на той же выборке. Примером применения данного подхода является \cite{journals/corr/HintonVD15}. В работе \cite{conf/cvpr/PassalisTT20} предложен подход к дистилляции знаний, позволяющий переносить знания на модель с архитектурой, значительно отличающейся от архитектуры модели-учителя.

Предлагается представление задачи в виде двухуровневой оптимизации. На первом уровне оптимизации происходит оптимизация параметров модели, на втором уровне --- ее гиперпараметров. Данный подход описан в работах \cite{journals/corr/LuketinaBR15, journals/anor/BakhteevS20, journals/corr/MaclaurinDA15}. В работе \cite{journals/corr/LuketinaBR15} рассматривается жадный градиентный метод оптимизации гиперпараметров, в работе \cite{journals/anor/BakhteevS20} сравниваются различные градиентные методы оптимизации гиперпараметров, а также метод случайного поиска.

В работе рассматривается вид задачи оптимизации, а также различные виды оператора оптимизации. Данный подход с использованием нейросети LSTM описан в работе \cite{journals/corr/AndrychowiczDGH16}. Вычислительный эксперимент проводится на выборке изображений CIFAR-10.

\section{Название раздела}
Данный документ демонстрирует оформление статьи,
подаваемой в электронную систему подачи статей \url{http://jmlda.org/papers} для публикации в журнале <<Машинное обучение и анализ данных>>.
Более подробные инструкции по~стилевому файлу \texttt{jmlda.sty} и~использованию издательской системы \LaTeXe\
находятся в~документе \texttt{authors-guide.pdf}.
Работу над статьёй удобно начинать с~правки \TeX-файла данного документа.

Обращаем внимание, что данный документ должен быть сохранен в кодировке~\verb'UTF-8 without BOM'.
Для смены кодировки рекомендуется пользоваться текстовыми редакторами \verb'Sublime Text' или \verb'Notepad++'.

\paragraph{Название параграфа}
Разделы и~параграфы, за исключением списков литературы, нумеруются.

\section{Заключение}
Желательно, чтобы этот раздел был, причём он не~должен дословно повторять аннотацию.
Обычно здесь отмечают, каких результатов удалось добиться, какие проблемы остались открытыми.

%%%% если имеется doi цитируемого источника, необходимо его указать, см. пример в \bibitem{article}
%%%% DOI публикации, зарегистрированной в системе Crossref, можно получить по адресу http://www.crossref.org/guestquery/

\bibliographystyle{bibstyle.bst}
\bibliography{bibliography.bib}


%%%% если имеется doi цитируемого источника, необходимо его указать, см. пример в \bibitem{article}
%%%% DOI публикации, зарегистрированной в системе Crossref, можно получить по адресу http://www.crossref.org/guestquery/.

\end{document}
