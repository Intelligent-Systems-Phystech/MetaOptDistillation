{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T18:03:35.655109Z",
     "start_time": "2021-09-07T18:03:34.649330Z"
    }
   },
   "outputs": [],
   "source": [
    "from resnet import *\n",
    "from fashionmnist_net import *\n",
    "from cnn_fmnist import *\n",
    "from resnet_fmnist import *\n",
    "from fashionmnist_dataset import *    \n",
    "import torch as t \n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "from numpy import polyfit\n",
    "from numpy import polyval\n",
    "import tqdm\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.cm as cm\n",
    "import json\n",
    "import hyperparams\n",
    "from importlib import reload\n",
    "from scipy.interpolate import interp1d\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T18:03:35.793064Z",
     "start_time": "2021-09-07T18:03:35.670248Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader, train_loader_no_augumentation = fashionmnist_loader(batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T18:03:36.101381Z",
     "start_time": "2021-09-07T18:03:36.099284Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T08:50:15.834151Z",
     "start_time": "2021-09-07T08:50:08.558639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-07 11:50:09--  https://github.com/passalis/pkth/blob/master/cifar10/models/resnet18_cifar10.model?raw=true\n",
      "Распознаётся github.com (github.com)… 140.82.121.4\n",
      "Подключение к github.com (github.com)|140.82.121.4|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://github.com/passalis/pkth/raw/master/cifar10/models/resnet18_cifar10.model [переход]\n",
      "--2021-09-07 11:50:09--  https://github.com/passalis/pkth/raw/master/cifar10/models/resnet18_cifar10.model\n",
      "Повторное использование соединения с github.com:443.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://raw.githubusercontent.com/passalis/pkth/master/cifar10/models/resnet18_cifar10.model [переход]\n",
      "--2021-09-07 11:50:09--  https://raw.githubusercontent.com/passalis/pkth/master/cifar10/models/resnet18_cifar10.model\n",
      "Распознаётся raw.githubusercontent.com (raw.githubusercontent.com)… 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Подключение к raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 44730527 (43M) [application/octet-stream]\n",
      "Сохранение в: «resnet18_cifar10.model?raw=true»\n",
      "\n",
      "resnet18_cifar10.mo 100%[===================>]  42,66M  11,5MB/s    за 4,0s    \n",
      "\n",
      "2021-09-07 11:50:15 (10,8 MB/s) - «resnet18_cifar10.model?raw=true» сохранён [44730527/44730527]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://github.com/passalis/pkth/blob/master/cifar10/models/resnet18_cifar10.model?raw=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T18:03:39.003506Z",
     "start_time": "2021-09-07T18:03:39.001126Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_num = 100\n",
    "# epoch_num = 50\n",
    "\n",
    "run_num = 1 # количество запусков эксперимента\n",
    "\n",
    "# версия нужна, чтобы различать старые и новые результаты экспериментов. \n",
    "# менять нужно каждый раз, когда есть хотя бы незначительные изменения в эксперименте\n",
    "experiment_version = '1'\n",
    "\n",
    "validate_every_epoch = 5 \n",
    "\n",
    "# train_splines_every_epoch = 5 # каждые 5 эпох отслеживать траекторию гиперпараметров\n",
    "# train_splines_every_epoch = 2\n",
    "# train_splines_every_epoch = 3\n",
    "# train_splines_every_epoch = 10\n",
    "\n",
    "# размер мини-эпохи в батчах, за которую у нас производится либо обучение спайлов, либо их использование\n",
    "# mini_epoch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T18:06:55.687255Z",
     "start_time": "2021-09-07T18:06:06.742174Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:165.9914093017578:   1%|▏         | 7/469 [00:48<53:42,  6.98s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-74109088d9d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'current loss:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# teacher = ResNet18(10).to(device)\n",
    "# teacher.load_state_dict(t.load('resnet18_cifar10.model?raw=true', map_location=device), )\n",
    "# teacher.eval()\n",
    "\n",
    "class_num=10\n",
    "seed=42\n",
    "tr_load=train_loader_no_augumentation\n",
    "t_load=test_loader\n",
    "validate_every_epoch=validate_every_epoch\n",
    "lr0=1.0\n",
    "\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "np.random.seed(seed)\n",
    "t.manual_seed(seed)\n",
    "\n",
    "for _ in range(run_num):\n",
    "    internal_results = []\n",
    "\n",
    "    teacher = ResNet18(class_num).to(device)\n",
    "    optim = t.optim.SGD(teacher.parameters(), lr=lr0)    \n",
    "    scheduler = t.optim.lr_scheduler.StepLR(optim, step_size=10, gamma=0.5)   \n",
    "\n",
    "    for e in range(epoch_num):\n",
    "        tq = tqdm.tqdm(tr_load)\n",
    "        losses = []\n",
    "\n",
    "        for batch_id, (x,y) in enumerate(tq):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            teacher.zero_grad()           \n",
    "            out = teacher(x)\n",
    "            teacher_loss = crit(out, y)                                                      \n",
    "            loss = teacher_loss\n",
    "\n",
    "            losses.append(loss.cpu().detach().numpy())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            tq.set_description('current loss:{}'.format(np.mean(losses[-10:])))        \n",
    "\n",
    "        if e==0 or (e+1)%validate_every_epoch == 0: # если номер эпохи делится на 5 или эпоха - первая             \n",
    "            test_loss = []\n",
    "            teacher.eval()\n",
    "\n",
    "            for x,y in t_load:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)                            \n",
    "                test_loss.append(crit(teacher(x), y).detach().cpu().numpy())                 \n",
    "\n",
    "            test_loss = float(np.mean(test_loss))\n",
    "            acc = float(accuracy(student, t_load))\n",
    "            teacher.train()\n",
    "\n",
    "            internal_results.append({'epoch': e, 'test loss':test_loss, 'accuracy':acc})\n",
    "\n",
    "            print (internal_results[-1])\n",
    "        scheduler.step()\n",
    "    with open('../log/exp'+exp_ver+'_resnet.jsonl', 'a') as out:\n",
    "        out.write(json.dumps({'results':internal_results, 'version': exp_ver})+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T18:03:40.824146Z",
     "start_time": "2021-09-07T18:03:40.629523Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'teacher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-456bd6ca7595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'teacher' is not defined"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with t.no_grad():\n",
    "    for x,y in train_loader_no_augumentation:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = teacher(x)\n",
    "        correct += t.eq(t.argmax(out, 1), y).sum()\n",
    "        total+=len(x)\n",
    "print ('teacher accuracy on train', correct/total)        \n",
    "        \n",
    "correct = 0\n",
    "total = 0\n",
    "with t.no_grad():\n",
    "    for x,y in test_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = teacher(x)\n",
    "        correct += t.eq(t.argmax(out, 1), y).sum()\n",
    "        total+=len(x)\n",
    "print ('teacher accuracy on test', correct/total)        \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = []\n",
    "with t.no_grad():\n",
    "    for x,y in train_loader_no_augumentation:\n",
    "        x = x.to(device)        \n",
    "        out = teacher(x)\n",
    "        logits.append(out.cpu().detach().numpy())\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('logits_resnet_fmnist', np.vstack(logits), allow_pickle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/passalis/pkth/blob/master/cifar10/models/aux_pkt.model?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T17:49:25.295959Z",
     "start_time": "2021-09-07T17:49:25.289329Z"
    }
   },
   "outputs": [],
   "source": [
    "teacher = FMNIST_CNN(10).to(device)\n",
    "# teacher.load_state_dict(t.load('aux_pkt.model?raw=true', map_location=device), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-07T17:58:33.744572Z",
     "start_time": "2021-09-07T17:58:20.651674Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current loss:0.6560705900192261:  39%|███▉      | 185/469 [00:13<00:20, 14.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3e5d776930d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'current loss:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class_num=10\n",
    "seed=42\n",
    "tr_load=train_loader_no_augumentation\n",
    "t_load=test_loader\n",
    "validate_every_epoch=validate_every_epoch\n",
    "lr0=1.0\n",
    "\n",
    "crit = nn.CrossEntropyLoss()\n",
    "np.random.seed(seed)\n",
    "t.manual_seed(seed)\n",
    "\n",
    "for _ in range(run_num):\n",
    "    internal_results = []\n",
    "\n",
    "    teacher = FMNIST_CNN(class_num).to(device)\n",
    "    optim = t.optim.SGD(teacher.parameters(), lr=lr0)    \n",
    "    scheduler = t.optim.lr_scheduler.StepLR(optim, step_size=10, gamma=0.5)   \n",
    "\n",
    "    for e in range(epoch_num):\n",
    "        tq = tqdm.tqdm(tr_load)\n",
    "        losses = []\n",
    "\n",
    "        for batch_id, (x,y) in enumerate(tq):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            teacher.zero_grad()           \n",
    "            out = teacher(x)\n",
    "            teacher_loss = crit(out, y)                                                      \n",
    "            loss = teacher_loss\n",
    "\n",
    "            losses.append(loss.cpu().detach().numpy())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            tq.set_description('current loss:{}'.format(np.mean(losses[-10:])))        \n",
    "\n",
    "        if e==0 or (e+1)%validate_every_epoch == 0: # если номер эпохи делится на 5 или эпоха - первая             \n",
    "            test_loss = []\n",
    "            teacher.eval()\n",
    "\n",
    "            for x,y in t_load:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)                            \n",
    "                test_loss.append(crit(teacher(x), y).detach().cpu().numpy())                 \n",
    "\n",
    "            test_loss = float(np.mean(test_loss))\n",
    "            acc = float(accuracy(student, t_load))\n",
    "            teacher.train()\n",
    "\n",
    "            internal_results.append({'epoch': e, 'test loss':test_loss, 'accuracy':acc})\n",
    "\n",
    "            print (internal_results[-1])\n",
    "        scheduler.step()\n",
    "    with open('../log/exp'+exp_ver+'_cnn.jsonl', 'a') as out:\n",
    "        out.write(json.dumps({'results':internal_results, 'version': exp_ver})+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with t.no_grad():\n",
    "    for x,y in train_loader_no_augumentation:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = teacher(x)\n",
    "        correct += t.eq(t.argmax(out, 1), y).sum()\n",
    "        total+=len(x)\n",
    "print ('teacher accuracy on train', correct/total)        \n",
    "        \n",
    "correct = 0\n",
    "total = 0\n",
    "with t.no_grad():\n",
    "    for x,y in test_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = teacher(x)\n",
    "        correct += t.eq(t.argmax(out, 1), y).sum()\n",
    "        total+=len(x)\n",
    "print ('teacher accuracy on test', correct/total)        \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = []\n",
    "with t.no_grad():\n",
    "    for x,y in train_loader_no_augumentation:\n",
    "        x = x.to(device)        \n",
    "        out = teacher(x)\n",
    "        logits.append(out.cpu().detach().numpy())\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('logits_cnn_fmnist', np.vstack(logits), allow_pickle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.804px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
